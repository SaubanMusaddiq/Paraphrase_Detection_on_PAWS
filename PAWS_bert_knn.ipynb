{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PAWS_bert_knn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afKIJtIYAJbB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSJwRUeOaU8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU5SpiRbafL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9tyOcv8ajRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer,BertForSequenceClassification,AdamW,get_linear_schedule_with_warmup, BertModel\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import wget\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from torch.nn import CrossEntropyLoss, MSELoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMniANMVhPaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32zhf2Jari8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get GPU name\n",
        "gpu=tf.test.gpu_device_name()\n",
        "print(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFZzH4uZbtcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device=torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' %torch.cuda.device_count())\n",
        "    print('We will use the GPU:',torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5STP5jK7b2Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download the PAWS Wiki dataset\n",
        "url='https://storage.googleapis.com/paws/english/paws_wiki_labeled_final.tar.gz'\n",
        "\n",
        "if not os.path.exists('./paws_wiki_labeled_final.tar.gz'):\n",
        "    wget.download(url, './paws_wiki_labeled_final.tar.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XZVYQpbczQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./pawsWiki_l_final/'):\n",
        "    !tar -xvf paws_wiki_labeled_final.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRyRD-Z4dL74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get training and validation data\n",
        "train=pd.read_csv('./final/train.tsv',sep='\\t')\n",
        "print(train.shape)\n",
        "print(train.head())\n",
        "\n",
        "val=pd.read_csv('./final/dev.tsv',sep='\\t')\n",
        "test=pd.read_csv('./final/test.tsv',sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmg6y81Y9n97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbCVW3jAe_pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data Preprocessing and tensor generation\n",
        "seed=2\n",
        "  \n",
        "train=train.sample(n=49401,random_state=seed)\n",
        "tokenized_train=tokenizer.batch_encode_plus(train.iloc[:,1:3].to_numpy().tolist(),max_length=128,pad_to_max_length=True,return_tensors='pt')\n",
        "labels_train=torch.tensor(train.label.values[:])\n",
        "\n",
        "val=val.sample(n=8000,random_state=seed)\n",
        "tokenized_val=tokenizer.batch_encode_plus(val.iloc[:,1:3].to_numpy().tolist(),max_length=128,pad_to_max_length=True,return_tensors='pt')\n",
        "labels_val=torch.tensor(val.label.values[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH_FXdriCkqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test.sample(n=1000,random_state=seed)\n",
        "tokenized_test=tokenizer.batch_encode_plus(test.iloc[:,1:3].to_numpy().tolist(),max_length=128,pad_to_max_length=True,return_tensors='pt')\n",
        "labels_test=torch.tensor(test.label.values[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTGGuyaygNsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "train_data=TensorDataset(tokenized_train['input_ids'],tokenized_train['attention_mask'],tokenized_train['token_type_ids'],labels_train)\n",
        "train_sampler=RandomSampler(train_data)\n",
        "train_dataloader=DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data=TensorDataset(tokenized_val['input_ids'],tokenized_val['attention_mask'],tokenized_val['token_type_ids'],labels_val)\n",
        "val_sampler=RandomSampler(val_data)\n",
        "val_dataloader=DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEhcCCjDHOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data=TensorDataset(tokenized_test['input_ids'],tokenized_test['attention_mask'],tokenized_test['token_type_ids'],labels_test)\n",
        "test_sampler=RandomSampler(test_data)\n",
        "test_dataloader=DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jijz2HzJX93w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CBERT(nn.Module):\n",
        "    def __init__(self,num_labels):\n",
        "        super(CBERT, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, 2)\n",
        "        \n",
        "    def forward(self, input_ids,token_type,attention_mask,labels=None):\n",
        "        outputs = self.bert(input_ids,token_type_ids=token_type,attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output_dp = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output_dp)\n",
        "\n",
        "        outputs = (logits,pooled_output) + outputs[2:]\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "                      \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6OYP-63gP72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bert Model transformer with a single sequence classification layer on top\n",
        "# model=BertForSequenceClassification.from_pretrained('bert-base-cased',num_labels=2,output_attentions=False,output_hidden_states=True)\n",
        "model = CBERT(2)\n",
        "model.cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m-u0D9OjUMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=AdamW(model.parameters(),lr=2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXqOovC8jsFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=4\n",
        "\n",
        "#Training steps is no_of_batches*no_of_epochs\n",
        "total_steps=len(train_dataloader)*epochs\n",
        "\n",
        "#Learning rate scheduler\n",
        "scheduler=get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mnfCjqum9Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of predictions\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    #return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "    return accuracy_score(pred_flat , labels_flat)\n",
        "\n",
        "\n",
        "def flat_precision(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return precision_score(pred_flat , labels_flat)\n",
        "    \n",
        "def flat_recall(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return recall_score(pred_flat , labels_flat)\n",
        "    \n",
        "def flat_f1score(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    #return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "    return f1_score(pred_flat , labels_flat)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6mMmb3xa16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBDB9N8nJEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    #Put model into training mode\n",
        "    model.train()\n",
        "\n",
        "    total_loss=0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        #Unpack the training batch\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_attention_mask=batch[1].to(device)\n",
        "        b_token_type = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        #Clear previously calculated gradients before performing a backward pass\n",
        "        #model.zero_grad()        //Not sure if useful or not\n",
        "\n",
        "        #Perform a forward pass and get the loss\n",
        "        outputs=model(b_input_ids,b_token_type,b_attention_mask,b_labels)\n",
        "\n",
        "        # logits = outputs[0]\n",
        "        \n",
        "        # #Move logits and labels to CPU\n",
        "        # logits = logits.detach().cpu().numpy()\n",
        "        # label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # #Calculate the accuracy for this batch of train sentences.\n",
        "        # tmp_train_accuracy = flat_accuracy(logits, label_ids)\n",
        "        # tain_accuracy += tmp_train_accuracy\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        #Perform backward pass to calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        #Clip the norm of the gradients to 1.0.\n",
        "        #Used to prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        #Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        #Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    #Avg loss over training data for an epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    # print(\"  Acerage train Accuracy: {0:.2f}\".format(tain_accuracy/len(train_dataloader)))\n",
        "\n",
        "\n",
        "    #### Validation\n",
        "\n",
        "    #Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    #Tracking variables \n",
        "    val_accuracy=0\n",
        "    val_precision = 0\n",
        "    val_recall = 0\n",
        "    val_f1score = 0\n",
        "    nb_val_steps=0\n",
        "\n",
        "    #Evaluate data for one epoch\n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        #Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        #Unpack the inputs from dataloader\n",
        "        b_input_ids,b_attention_mask, b_token_type, b_labels = batch\n",
        "        \n",
        "        #Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "        with torch.no_grad():        \n",
        "            outputs = model(b_input_ids,b_token_type,b_attention_mask)\n",
        "        \n",
        "        #Get the \"logits\" output by the model. The \"logits\" are output values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        #Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        #Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_val_accuracy = flat_accuracy(logits, label_ids)\n",
        "        tmp_val_precision = flat_precision(logits, label_ids)\n",
        "        tmp_val_recall = flat_recall(logits, label_ids)\n",
        "        tmp_val_f1score = flat_f1score(logits, label_ids)\n",
        "          \n",
        "\n",
        "        #Accumulate the total accuracy.\n",
        "        val_accuracy += tmp_val_accuracy\n",
        "        val_precision += tmp_val_precision\n",
        "        val_recall += tmp_val_recall\n",
        "        val_f1score += tmp_val_f1score\n",
        "        #Track the number of batches\n",
        "        nb_val_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"Average Val  Accuracy: {0:.2f}\".format(val_accuracy/nb_val_steps))\n",
        "    print(\"Average Val  precison: {0:.2f}\".format(val_precision/nb_val_steps))\n",
        "    print(\"Average Val  recall: {0:.2f}\".format(val_recall/nb_val_steps))\n",
        "    print(\"Average Val  f1score: {0:.2f}\".format(val_f1score/nb_val_steps))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9dZBwKKSQUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62jB1_e7TWgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'paws_49k_4e_cbert.pt'\n",
        "path = F\"/content/gdrive/My Drive/models/paws/{model_save_name}\" \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqkHUu2KwsDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfHGrlh-T2c1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load(path))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNFS4YNIwQlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sample = test.sample(n=500,random_state=seed)\n",
        "tokenized_test=tokenizer.batch_encode_plus(test_sample.iloc[:,1:3].to_numpy().tolist(),max_length=128,pad_to_max_length=True,return_tensors='pt')\n",
        "labels_test=torch.tensor(test_sample.label.values[:])\n",
        "batch = tokenized_test['input_ids'],tokenized_test['attention_mask'],tokenized_test['token_type_ids'],labels_test\n",
        "\n",
        "batch = tuple(t.to(device) for t in batch)\n",
        "b_input_ids,b_attention_mask, b_token_type, b_labels = batch\n",
        "with torch.no_grad():        \n",
        "    test_outputs = model(b_input_ids,b_token_type,attention_mask=b_attention_mask)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOgKNaMUwNb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence_embeddings = test_outputs[1].tolist()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aj3KRVOpPV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentence_embeddings = [] \n",
        "labels_train = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHdloOEplFXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "    #Unpack the training batch\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_attention_mask=batch[1].to(device)\n",
        "    b_token_type = batch[2].to(device)\n",
        "    b_labels = batch[3].to(device)\n",
        "    labels_train.extend(b_labels)\n",
        "    #Clear previously calculated gradients before performing a backward pass\n",
        "    #model.zero_grad()        //Not sure if useful or not\n",
        "\n",
        "    #Perform a forward pass and get the loss\n",
        "    outputs=model(b_input_ids,b_token_type,b_attention_mask)[1]\n",
        "    # print(outputs[1].shape)\n",
        "    train_sentence_embeddings.extend(outputs.tolist())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDnrRM_lUyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp ={}\n",
        "import scipy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KlFKHpwlajg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp = {}\n",
        "for i in range(2,10):\n",
        "  closest_n = 7\n",
        "  correct_pred = 0\n",
        "  for test_idx,test_embedding in enumerate(test_sentence_embeddings[:10]):\n",
        "    distances = scipy.spatial.distance.cdist([test_embedding], train_sentence_embeddings, \"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "    count_yes = 0\n",
        "    for idx, distance in results[0:closest_n]:\n",
        "    #         print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))\n",
        "        if(labels_train[idx].tolist() == 1):\n",
        "            count_yes +=1\n",
        "    pred = 0 \n",
        "    if(count_yes>closest_n/2):\n",
        "        pred = 1\n",
        "    if(pred ==  labels_test[test_idx]):\n",
        "        correct_pred+=1\n",
        "  print(closest_n)\n",
        "  print(float(correct_pred)/len(labels_test[:100]))\n",
        "  mp[closest_n] = float(correct_pred)/len(labels_test[:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAKdP9sRS3Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}